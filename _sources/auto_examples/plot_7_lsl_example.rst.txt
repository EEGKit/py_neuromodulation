
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_7_lsl_example.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_7_lsl_example.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_7_lsl_example.py:


Lab Streaming Layer (LSL) Example
=================================

This toolbox implements the lsl ecosystem which can be utilized for offline use cases as well as live streamings
In this example the data introduced in the first demo is being analyzed
in a similar manner, This time however integrating an lsl stream.

.. GENERATED FROM PYTHON SOURCE LINES 12-23

.. code-block:: Python

    from matplotlib import pyplot as plt

    from py_neuromodulation import (
        nm_mnelsl_generator,
        nm_IO,
        nm_define_nmchannels,
        nm_analysis,
        nm_stream_offline,
        nm_settings,
    )








.. GENERATED FROM PYTHON SOURCE LINES 24-25

Let’s get the example data from the provided BIDS dataset and create the nm_channels DataFrame.

.. GENERATED FROM PYTHON SOURCE LINES 25-53

.. code-block:: Python


    (
        RUN_NAME,
        PATH_RUN,
        PATH_BIDS,
        PATH_OUT,
        datatype,
    ) = nm_IO.get_paths_example_data()

    (
        raw,
        data,
        sfreq,
        line_noise,
        coord_list,
        coord_names,
    ) = nm_IO.read_BIDS_data(PATH_RUN=PATH_RUN)

    nm_channels = nm_define_nmchannels.set_channels(
        ch_names=raw.ch_names,
        ch_types=raw.get_channel_types(),
        reference="default",
        bads=raw.info["bads"],
        new_names="default",
        used_types=("ecog", "dbs", "seeg"),
        target_keywords=["MOV_RIGHT"],
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Extracting parameters from /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/data/sub-testsub/ses-EphysMedOff/ieeg/sub-testsub_ses-EphysMedOff_task-gripforce_run-0_ieeg.vhdr...
    Setting channel info structure...
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_IO.py:63: RuntimeWarning: Did not find any events.tsv associated with sub-testsub_ses-EphysMedOff_task-gripforce_run-0.

    The search_str was "/home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/data/sub-testsub/**/ieeg/sub-testsub_ses-EphysMedOff*events.tsv"
      raw_arr = read_raw_bids(bids_path)
    Reading channel info from /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/data/sub-testsub/ses-EphysMedOff/ieeg/sub-testsub_ses-EphysMedOff_task-gripforce_run-0_channels.tsv.
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_IO.py:63: RuntimeWarning: The unit for channel(s) MOV_RIGHT has changed from V to NA.
      raw_arr = read_raw_bids(bids_path)
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_IO.py:63: RuntimeWarning: Other is not an MNE-Python coordinate frame for IEEG data and so will be set to 'unknown'
      raw_arr = read_raw_bids(bids_path)
    Reading electrode coords from /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/data/sub-testsub/ses-EphysMedOff/ieeg/sub-testsub_ses-EphysMedOff_space-mni_electrodes.tsv.
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_IO.py:63: RuntimeWarning: There are channels without locations (n/a) that are not marked as bad: ['MOV_RIGHT']
      raw_arr = read_raw_bids(bids_path)
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_IO.py:63: RuntimeWarning: Not setting position of 1 misc channel found in montage:
    ['MOV_RIGHT']
    Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.
      raw_arr = read_raw_bids(bids_path)




.. GENERATED FROM PYTHON SOURCE LINES 54-66

Playing the Data
----------------

Now we need our data to be represeted in the LSL stream.
For this example an mne_lsl.Player is utilized, which is playing our earlier
recorded data. However, you could make use of any LSL source (live or
offline).
If you want to bind your own data source, make sure to specify the
necessary parameters (data type, type, name) accordingly.
If you are unsure about the parameters of your data source you can
always search for available lsl streams.


.. GENERATED FROM PYTHON SOURCE LINES 66-75

.. code-block:: Python


    settings = nm_settings.get_default_settings()
    settings = nm_settings.set_settings_fast_compute(settings)

    player = nm_mnelsl_generator.LSLOfflinePlayer(
        raw=raw, stream_name="example_stream"
    )  # TODO: add different keyword

    player.start_player(chunk_size=30)







.. GENERATED FROM PYTHON SOURCE LINES 76-82

Creating the LSLStream object
-----------------------------

Next let’s create a Stream analog to the First Demo’s example However as
we run the stream, we will set the *lsl-stream* value to True and pass
the stream name we earlier declared when initializing the player object

.. GENERATED FROM PYTHON SOURCE LINES 82-89

.. code-block:: Python


    settings["features"]["welch"] = False
    settings["features"]["fft"] = True
    settings["features"]["bursts"] = False
    settings["features"]["sharpwave_analysis"] = False
    settings["features"]["coherence"] = False








.. GENERATED FROM PYTHON SOURCE LINES 90-98

.. code-block:: Python

    stream = nm_stream_offline.Stream(
        sfreq=sfreq,
        nm_channels=nm_channels,
        settings=settings,
        coord_list=coord_list,
        verbose=True,
        line_noise=line_noise,
    )







.. GENERATED FROM PYTHON SOURCE LINES 99-100

We then simply have to set the `stream_lsl` parameter to be `True` and specify the `stream_lsl_name`.

.. GENERATED FROM PYTHON SOURCE LINES 100-109

.. code-block:: Python


    features = stream.run(
        stream_lsl=True,
        plot_lsl=False,
        stream_lsl_name="example_stream",
        out_path_root=PATH_OUT,
        folder_name=RUN_NAME,
    )








.. GENERATED FROM PYTHON SOURCE LINES 110-112

We can then look at the computed features and check if the streamed data was processed correctly.
This can be verified by the time label:

.. GENERATED FROM PYTHON SOURCE LINES 112-116

.. code-block:: Python


    plt.plot(features["time"], features["MOV_RIGHT"])





.. image-sg:: /auto_examples/images/sphx_glr_plot_7_lsl_example_001.png
   :alt: plot 7 lsl example
   :srcset: /auto_examples/images/sphx_glr_plot_7_lsl_example_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    [<matplotlib.lines.Line2D object at 0x7f6709dd1720>]



.. GENERATED FROM PYTHON SOURCE LINES 117-122

Feature Analysis of Movement
----------------------------
We can now check the movement averaged features of an ECoG channel.
Note that the path was here adapted to be documentation build compliant.
%%

.. GENERATED FROM PYTHON SOURCE LINES 122-136

.. code-block:: Python


    feature_reader = nm_analysis.Feature_Reader(feature_dir=PATH_OUT, feature_file=RUN_NAME)
    feature_reader.label_name = "MOV_RIGHT"
    feature_reader.label = feature_reader.feature_arr["MOV_RIGHT"]

    feature_reader.plot_target_averaged_channel(
        ch="ECOG_RIGHT_0",
        list_feature_keywords=None,
        epoch_len=4,
        threshold=0.5,
        ytick_labelsize=7,
        figsize_x=12,
        figsize_y=12,
    )



.. image-sg:: /auto_examples/images/sphx_glr_plot_7_lsl_example_002.png
   :alt: Movement aligned features channel: ECOG_RIGHT_0, MOV_RIGHT
   :srcset: /auto_examples/images/sphx_glr_plot_7_lsl_example_002.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 23.472 seconds)


.. _sphx_glr_download_auto_examples_plot_7_lsl_example.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_7_lsl_example.ipynb <plot_7_lsl_example.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_7_lsl_example.py <plot_7_lsl_example.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
