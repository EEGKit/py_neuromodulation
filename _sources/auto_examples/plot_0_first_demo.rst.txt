
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_0_first_demo.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_0_first_demo.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_0_first_demo.py:


First Demo
==========

This Demo will showcase the feature estimation and
exemplar analysis using simulated data.

.. GENERATED FROM PYTHON SOURCE LINES 8-16

.. code-block:: Python


    import numpy as np
    from matplotlib import pyplot as plt

    import py_neuromodulation as nm

    from py_neuromodulation import nm_analysis, nm_define_nmchannels, nm_plots, nm_settings








.. GENERATED FROM PYTHON SOURCE LINES 17-20

Data Simulation
---------------
We will now generate some exemplar data with 10 second duration for 6 channels with a sample rate of 1 kHz.

.. GENERATED FROM PYTHON SOURCE LINES 20-47

.. code-block:: Python



    def generate_random_walk(NUM_CHANNELS, TIME_DATA_SAMPLES):
        # from https://towardsdatascience.com/random-walks-with-python-8420981bc4bc
        dims = NUM_CHANNELS
        step_n = TIME_DATA_SAMPLES - 1
        step_set = [-1, 0, 1]
        origin = (np.random.random([1, dims]) - 0.5) * 1  # Simulate steps in 1D
        step_shape = (step_n, dims)
        steps = np.random.choice(a=step_set, size=step_shape)
        path = np.concatenate([origin, steps]).cumsum(0)
        return path.T


    NUM_CHANNELS = 6
    sfreq = 1000
    TIME_DATA_SAMPLES = 10 * sfreq
    data = generate_random_walk(NUM_CHANNELS, TIME_DATA_SAMPLES)
    time = np.arange(0, TIME_DATA_SAMPLES / sfreq, 1 / sfreq)

    plt.figure(figsize=(8, 4), dpi=100)
    for ch_idx in range(data.shape[0]):
        plt.plot(time, data[ch_idx, :])
    plt.xlabel("Time [s]")
    plt.ylabel("Amplitude")
    plt.title("Example random walk data")




.. image-sg:: /auto_examples/images/sphx_glr_plot_0_first_demo_001.png
   :alt: Example random walk data
   :srcset: /auto_examples/images/sphx_glr_plot_0_first_demo_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    Text(0.5, 1.0, 'Example random walk data')



.. GENERATED FROM PYTHON SOURCE LINES 48-95

Now let’s define the necessary setup files we will be using for data
preprocessing and feature estimation. Py_neuromodualtion is based on two
parametrization files: the *nm_channels.tsv* and the *nm_setting.json*.

nm_channels
~~~~~~~~~~~

The *nm_channel* dataframe. This dataframe contains the columns

+-----------------------------------+-----------------------------------+
| Column name                       | Description                       |
+===================================+===================================+
| **name**                          | name of the channel               |
+-----------------------------------+-----------------------------------+
| **rereference**                   | different channel name for        |
|                                   | bipolar re-referencing, or        |
|                                   | average for common average        |
|                                   | re-referencing                    |
+-----------------------------------+-----------------------------------+
| **used**                          | 0 or 1, channel selection         |
+-----------------------------------+-----------------------------------+
| **target**                        | 0 or 1, for some decoding         |
|                                   | applications we can define target |
|                                   | channels, e.g. EMG channels       |
+-----------------------------------+-----------------------------------+
| **type**                          | channel type according to the     |
|                                   | `mne-python`_ toolbox             |
|                                   |                                   |
|                                   |                                   |
|                                   |                                   |
|                                   |                                   |
|                                   | e.g. ecog, eeg, ecg, emg, dbs,    |
|                                   | seeg etc.                         |
+-----------------------------------+-----------------------------------+
| **status**                        | good or bad, used for channel     |
|                                   | quality indication                |
+-----------------------------------+-----------------------------------+
| **new_name**                      | this keyword can be specified to  |
|                                   | indicate for example the used     |
|                                   | rereferncing scheme               |
+-----------------------------------+-----------------------------------+

.. _mne-python: https://mne.tools/stable/auto_tutorials/raw/10_raw_overview.html#sphx-glr-auto-tutorials-raw-10-raw-overview-py

The :class:`~nm_stream_abc` can either be created as a *.tsv* text file, or as a pandas
DataFrame. There are some helper functions that let you create the
nm_channels without much effort:

.. GENERATED FROM PYTHON SOURCE LINES 95-102

.. code-block:: Python


    nm_channels = nm_define_nmchannels.get_default_channels_from_data(
        data, car_rereferencing=True
    )

    nm_channels






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>name</th>
          <th>rereference</th>
          <th>used</th>
          <th>target</th>
          <th>type</th>
          <th>status</th>
          <th>new_name</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>ch0</td>
          <td>average</td>
          <td>1</td>
          <td>0</td>
          <td>ecog</td>
          <td>good</td>
          <td>ch0-avgref</td>
        </tr>
        <tr>
          <th>1</th>
          <td>ch1</td>
          <td>average</td>
          <td>1</td>
          <td>0</td>
          <td>ecog</td>
          <td>good</td>
          <td>ch1-avgref</td>
        </tr>
        <tr>
          <th>2</th>
          <td>ch2</td>
          <td>average</td>
          <td>1</td>
          <td>0</td>
          <td>ecog</td>
          <td>good</td>
          <td>ch2-avgref</td>
        </tr>
        <tr>
          <th>3</th>
          <td>ch3</td>
          <td>average</td>
          <td>1</td>
          <td>0</td>
          <td>ecog</td>
          <td>good</td>
          <td>ch3-avgref</td>
        </tr>
        <tr>
          <th>4</th>
          <td>ch4</td>
          <td>average</td>
          <td>1</td>
          <td>0</td>
          <td>ecog</td>
          <td>good</td>
          <td>ch4-avgref</td>
        </tr>
        <tr>
          <th>5</th>
          <td>ch5</td>
          <td>average</td>
          <td>1</td>
          <td>0</td>
          <td>ecog</td>
          <td>good</td>
          <td>ch5-avgref</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 103-109

Using this function default channel names and a common average re-referencing scheme is specified.
Alternatively the *nm_define_nmchannels.set_channels* function can be used to pass each column values.

nm_settings
-----------
Next, we will initialize the nm_settings dictionary and use the default settings, reset them, and enable a subset of features:

.. GENERATED FROM PYTHON SOURCE LINES 109-114

.. code-block:: Python


    settings = nm_settings.get_default_settings()
    settings = nm_settings.reset_settings(settings)









.. GENERATED FROM PYTHON SOURCE LINES 115-133

The setting itself is a .json file which contains the parametrization for preprocessing, feature estimation, postprocessing and
definition with which sampling rate features are being calculated.
In this example `sampling_rate_features_hz` is specified to be 10 Hz, so every 100ms a new set of features is calculated.

For many features the `segment_length_features_ms` specifies the time dimension of the raw signal being used for feature calculation. Here it is specified to be 1000 ms.

We will now enable the features:

* fft
* bursts
* sharpwave

and stay with the default preprcessing methods:

* notch_filter
* re_referencing

and use *z-score* postprocessing normalization.

.. GENERATED FROM PYTHON SOURCE LINES 133-138

.. code-block:: Python


    settings["features"]["fft"] = True
    settings["features"]["bursts"] = True
    settings["features"]["sharpwave_analysis"] = True








.. GENERATED FROM PYTHON SOURCE LINES 139-140

We are now ready to go to instantiate the *Stream* and call the *run* method for feature estimation:

.. GENERATED FROM PYTHON SOURCE LINES 140-151

.. code-block:: Python


    stream = nm.Stream(
        settings=settings,
        nm_channels=nm_channels,
        verbose=True,
        sfreq=sfreq,
        line_noise=50,
    )

    features = stream.run(data)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_oscillatory.py:165: RuntimeWarning: divide by zero encountered in log10
      Z = np.log10(Z)
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_oscillatory.py:165: RuntimeWarning: divide by zero encountered in log10
      Z = np.log10(Z)
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_oscillatory.py:165: RuntimeWarning: divide by zero encountered in log10
      Z = np.log10(Z)
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_oscillatory.py:165: RuntimeWarning: divide by zero encountered in log10
      Z = np.log10(Z)
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_oscillatory.py:165: RuntimeWarning: divide by zero encountered in log10
      Z = np.log10(Z)
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_oscillatory.py:165: RuntimeWarning: divide by zero encountered in log10
      Z = np.log10(Z)
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_oscillatory.py:165: RuntimeWarning: divide by zero encountered in log10
      Z = np.log10(Z)
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_oscillatory.py:165: RuntimeWarning: divide by zero encountered in log10
      Z = np.log10(Z)
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_oscillatory.py:165: RuntimeWarning: divide by zero encountered in log10
      Z = np.log10(Z)
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_oscillatory.py:165: RuntimeWarning: divide by zero encountered in log10
      Z = np.log10(Z)
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_oscillatory.py:165: RuntimeWarning: divide by zero encountered in log10
      Z = np.log10(Z)
    /home/runner/.venv/lib/python3.10/site-packages/py_neuromodulation/nm_oscillatory.py:165: RuntimeWarning: divide by zero encountered in log10
      Z = np.log10(Z)




.. GENERATED FROM PYTHON SOURCE LINES 152-157

Feature Analysis
----------------

There is a lot of output, which we could omit by verbose being False, but let's have a look what was being computed.
We will therefore use the :class:`~nm_analysis` class to showcase some functions. For multi-run -or subject analysis we will pass here the feature_file "sub" as default directory:

.. GENERATED FROM PYTHON SOURCE LINES 157-162

.. code-block:: Python


    analyzer = nm_analysis.Feature_Reader(
        feature_dir=stream.PATH_OUT, feature_file=stream.PATH_OUT_folder_name
    )








.. GENERATED FROM PYTHON SOURCE LINES 163-164

Let's have a look at the resulting "feature_arr" DataFrame:

.. GENERATED FROM PYTHON SOURCE LINES 164-167

.. code-block:: Python


    analyzer.feature_arr.iloc[:10, :7]






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>ch0-avgref_fft_theta_mean</th>
          <th>ch0-avgref_fft_alpha_mean</th>
          <th>ch0-avgref_fft_low beta_mean</th>
          <th>ch0-avgref_fft_high beta_mean</th>
          <th>ch0-avgref_fft_low gamma_mean</th>
          <th>ch0-avgref_fft_high gamma_mean</th>
          <th>ch0-avgref_fft_HFA_mean</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>2.822929</td>
          <td>2.768317</td>
          <td>2.382831</td>
          <td>2.287676</td>
          <td>1.688218</td>
          <td>1.397053</td>
          <td>1.137972</td>
        </tr>
        <tr>
          <th>1</th>
          <td>2.796883</td>
          <td>2.691444</td>
          <td>2.461106</td>
          <td>2.151755</td>
          <td>1.620776</td>
          <td>1.418158</td>
          <td>1.110350</td>
        </tr>
        <tr>
          <th>2</th>
          <td>2.778462</td>
          <td>2.684753</td>
          <td>2.311408</td>
          <td>2.145524</td>
          <td>1.617802</td>
          <td>1.385141</td>
          <td>1.068343</td>
        </tr>
        <tr>
          <th>3</th>
          <td>2.781908</td>
          <td>2.652162</td>
          <td>2.551574</td>
          <td>2.162721</td>
          <td>1.746070</td>
          <td>1.459966</td>
          <td>1.133486</td>
        </tr>
        <tr>
          <th>4</th>
          <td>2.792896</td>
          <td>2.654855</td>
          <td>2.277807</td>
          <td>2.002319</td>
          <td>1.644357</td>
          <td>1.431955</td>
          <td>1.136145</td>
        </tr>
        <tr>
          <th>5</th>
          <td>2.737762</td>
          <td>2.760756</td>
          <td>2.394914</td>
          <td>2.139344</td>
          <td>1.709927</td>
          <td>1.412672</td>
          <td>1.148051</td>
        </tr>
        <tr>
          <th>6</th>
          <td>2.711349</td>
          <td>2.602644</td>
          <td>2.196959</td>
          <td>2.038932</td>
          <td>1.556131</td>
          <td>1.398210</td>
          <td>1.104945</td>
        </tr>
        <tr>
          <th>7</th>
          <td>2.689405</td>
          <td>2.468761</td>
          <td>2.197481</td>
          <td>2.095836</td>
          <td>1.547028</td>
          <td>1.373067</td>
          <td>1.087022</td>
        </tr>
        <tr>
          <th>8</th>
          <td>2.858857</td>
          <td>2.424042</td>
          <td>2.358998</td>
          <td>2.182848</td>
          <td>1.591264</td>
          <td>1.382344</td>
          <td>1.087393</td>
        </tr>
        <tr>
          <th>9</th>
          <td>2.520463</td>
          <td>2.459157</td>
          <td>2.332469</td>
          <td>2.159141</td>
          <td>1.611962</td>
          <td>1.450984</td>
          <td>1.170648</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 168-177

Seems like a lot of features were calculated. The `time` column tells us about each row time index.
For the 6 specified channels, it is each 31 features.
We can now use some in-built plotting functions for visualization.

.. note::

    Due to the nature of simulated data, some of the features have constant values, which are not displayed through the image normalization.



.. GENERATED FROM PYTHON SOURCE LINES 177-180

.. code-block:: Python


    analyzer.plot_all_features(ch_used="ch1")




.. image-sg:: /auto_examples/images/sphx_glr_plot_0_first_demo_002.png
   :alt: Feature Plot sub
   :srcset: /auto_examples/images/sphx_glr_plot_0_first_demo_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 181-187

.. code-block:: Python

    nm_plots.plot_corr_matrix(
        figsize=(25, 25),
        show_plot=True,
        feature=analyzer.feature_arr,
    )




.. image-sg:: /auto_examples/images/sphx_glr_plot_0_first_demo_003.png
   :alt: Correlation matrix
   :srcset: /auto_examples/images/sphx_glr_plot_0_first_demo_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Axes: title={'center': 'Correlation matrix'}>



.. GENERATED FROM PYTHON SOURCE LINES 188-190

The upper correlation matrix shows the correlation of every feature of every channel to every other.
This notebook demonstrated a first demo how features can quickly be generated. For further feature modalities and decoding applications check out the next notebooks.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 2.571 seconds)


.. _sphx_glr_download_auto_examples_plot_0_first_demo.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_0_first_demo.ipynb <plot_0_first_demo.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_0_first_demo.py <plot_0_first_demo.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
